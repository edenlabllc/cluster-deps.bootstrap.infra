{{- $gcpRegion := env "GCP_REGION" }}

# Default values for gcp-cluster.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

## GKE cluster configuration
cluster:
  ## The name of the cluster, required
  name: {{ env "NAME" }}

  # Project is the name of the project to deploy the cluster to, required.
  project: {{ env "GCP_PROJECT_ID" }}

  region: {{ $gcpRegion }}
  managed:
    spec:
      # NetworkSpec encapsulates all things related to the GCP network.
      network:
        # Name is the name of the network to be used.
        # The default name is "default"
        name: "default"
  spec:
    # Cluster network configuration.
    clusterNetwork:
      # # APIServerPort specifies the port the API Server should bind to.
      # # Defaults to 6443.
      apiServerPort: 443
      # The network ranges from which Pod networks are allocated.
      pods:
        cidrBlocks:
          - 192.168.0.0/16

controlPlane:
  spec:
    version: "v1.29.10"
    clusterNetwork:
      privateCluster:
        enablePrivateNodes: true

templates:
  spec: &machinePoolsTemplateSpec
    # LinuxNodeConfig specifies the settings for Linux agent nodes.
    linuxNodeConfig:
      cgroupMode: ~
      sysctls: []
    # Management specifies the node pool management options.
    management:
      # AutoRepair specifies whether the node auto-repair is enabled for the node
      # pool. If enabled, the nodes in this node pool will be monitored and, if
      # they fail health checks too many times, an automatic repair action will be
      # triggered.
      autoRepair: false
      # AutoUpgrade specifies whether node auto-upgrade is enabled for the node
      # pool. If enabled, node auto-upgrade helps keep the nodes in your node pool
      # up to date with the latest release version of Kubernetes.
      autoUpgrade: false
    # MaxPodsPerNode is constraint enforced on the max num of pods per node.
    maxPodsPerNode: 110
    scaling:
      enableAutoscaling: false
    # NodeLocations is the list of zones in which the NodePool's nodes should be located.
    # minItems 0 of type string
    nodeLocations:
      - "{{ $gcpRegion }}-a"
  specTemplate: &machinePoolsTemplateSpecTemplate
    metadata: {}
    spec:
      bootstrap:
          # DataSecretName is the name of the secret that stores the bootstrap data script.
          # If nil, the Machine should remain in the Pending state.
        dataSecretName: ""
      # NodeDeletionTimeout defines how long the controller will attempt to delete the Node that the Machine
      # hosts after the Machine is marked for deletion. A duration of 0 will retry deletion indefinitely.
      # Defaults to 10 seconds.
      nodeDeletionTimeout: "10s"
      # NodeDrainTimeout is the total amount of time that the controller will spend on draining a node.
      # The default value is 0, meaning that the node can be drained without any time limitations.
      # NOTE: NodeDrainTimeout is different from `kubectl drain --timeout`
      nodeDrainTimeout: "0s"
      # NodeVolumeDetachTimeout is the total amount of time that the controller will spend on waiting for all volumes
      # to be detached. The default value is 0, meaning that the volumes can be detached without any time limitations.
      nodeVolumeDetachTimeout: "0s"

machinePools:
  app:
    enabled: false
    annotations: {}
    labels: {}
    managed:
      spec:
        # AdditionalLabels is an optional set of tags to add to GCP resources managed by the GCP provider, in addition to the ones added by default.
        additionalLabels: {}
        # DiskSizeGb is the size of the disk attached to each node, specified in GB.
        # The smallest allowed disk size is 10GB. If unspecified, the default disk size is 100GB.
        diskSizeGb: 10
        # DiskType is type of the disk attached to each node.
        # "pd-standard", "pd-ssd", "pd-balanced"
        diskType: "pd-ssd"
        # KubernetesLabels specifies the labels to apply to the nodes of the node pool.
        kubernetesLabels:
          db: app
        # KubernetesTaints specifies the taints to apply to the nodes of the node pool.
        kubernetesTaints: []
          # - effect: "NoSchedule" # "NoSchedule", "NoExecute", "PreferNoSchedule"
          #   # Key is the key of the taint
          #   key: "key"
          #   # Value is the value of the taint
          #   value: "string"
        # MachineType is the name of a Google Compute Engine
        # (https://cloud.google.com/compute/docs/machine-types).
        # If unspecified, the default machine type is `e2-medium`.
        machineType: "n2-standard-2"
        <<: *machinePoolsTemplateSpec
    replicas: 10
    spec:
      template:
        <<: *machinePoolsTemplateSpecTemplate

  clickhouse:
    enabled: false
    annotations: {}
    labels: {}
    managed:
      spec:
        additionalLabels: {}
        diskSizeGb: 10
        diskType: "pd-ssd"
        kubernetesLabels:
          db: clickhouse
        kubernetesTaints:
          - effect: "NoSchedule"
            key: "key"
            value: "clickhouse"
        machineType: "n2-highcpu-2"
        <<: *machinePoolsTemplateSpec
    replicas: 2
    spec:
      template:
        <<: *machinePoolsTemplateSpecTemplate

  clickhouse-search:
    enabled: false
    annotations: {}
    labels: {}
    managed:
      spec:
        additionalLabels: {}
        diskSizeGb: 50
        diskType: "pd-ssd"
        kubernetesLabels:
          db: clickhouse-search
        kubernetesTaints:
          - effect: "NoSchedule"
            key: "key"
            value: "clickhouse-search"
        machineType: "n2-standard-2"
        <<: *machinePoolsTemplateSpec
    replicas: 2
    spec:
      template:
        <<: *machinePoolsTemplateSpecTemplate

  elastic:
    enabled: false
    annotations: {}
    labels: {}
    managed:
      spec:
        additionalLabels: {}
        diskSizeGb: 10
        diskType: "pd-ssd"
        kubernetesLabels:
          db: es
        kubernetesTaints:
          - effect: "NoSchedule"
            key: "key"
            value: "es"
        machineType: "n2-standard-2"
        <<: *machinePoolsTemplateSpec
    replicas: 1
    spec:
      template:
        <<: *machinePoolsTemplateSpecTemplate

  fhirpostgres:
    enabled: false
    annotations: {}
    labels: {}
    managed:
      spec:
        additionalLabels: {}
        diskSizeGb: 10
        diskType: "pd-ssd"
        kubernetesLabels:
          db: fhir-postgres
          fhir: postgres
        kubernetesTaints:
          - effect: "NoSchedule"
            key: "key"
            value: "fhir-postgres"
        machineType: "n2-highcpu-2"
        <<: *machinePoolsTemplateSpec
    replicas: 2
    spec:
      template:
        <<: *machinePoolsTemplateSpecTemplate

  kafka:
    enabled: false
    annotations: {}
    labels: {}
    managed:
      spec:
        additionalLabels: {}
        diskSizeGb: 10
        diskType: "pd-ssd"
        kubernetesLabels:
          db: kafka
        kubernetesTaints:
          - effect: "NoSchedule"
            key: "key"
            value: "kafka"
        machineType: "n2-standard-2"
        <<: *machinePoolsTemplateSpec
    replicas: 3
    spec:
      template:
        <<: *machinePoolsTemplateSpecTemplate

  loki:
    enabled: false
    annotations: {}
    labels: {}
    managed:
      spec:
        additionalLabels: {}
        diskSizeGb: 10
        diskType: "pd-ssd"
        kubernetesLabels:
          db: loki-stack
        kubernetesTaints:
          - effect: "NoSchedule"
            key: "key"
            value: "loki-stack"
        machineType: "n2-standard-2"
        <<: *machinePoolsTemplateSpec
    replicas: 1
    spec:
      template:
        <<: *machinePoolsTemplateSpecTemplate

  minio:
    enabled: false
    annotations: {}
    labels: {}
    managed:
      spec:
        additionalLabels: {}
        diskSizeGb: 10
        diskType: "pd-ssd"
        kubernetesLabels:
          db: minio
        kubernetesTaints:
          - effect: "NoSchedule"
            key: "key"
            value: "minio"
        machineType: "n2-standard-2"
        <<: *machinePoolsTemplateSpec
    replicas: 1
    spec:
      template:
        <<: *machinePoolsTemplateSpecTemplate

  mongodb:
    enabled: false
    annotations: {}
    labels: {}
    managed:
      spec:
        additionalLabels: {}
        diskSizeGb: 10
        diskType: "pd-ssd"
        kubernetesLabels:
          db: mongodb
        kubernetesTaints:
          - effect: "NoSchedule"
            key: "key"
            value: "mongodb"
        machineType: "n2-standard-2"
        <<: *machinePoolsTemplateSpec
    replicas: 1
    spec:
      template:
        <<: *machinePoolsTemplateSpecTemplate

  postgres:
    enabled: false
    annotations: {}
    labels: {}
    managed:
      spec:
        additionalLabels: {}
        diskSizeGb: 10
        diskType: "pd-ssd"
        kubernetesLabels:
          db: postgres
        kubernetesTaints:
          - effect: "NoSchedule"
            key: "key"
            value: "postgres"
        machineType: "n2-standard-2"
        <<: *machinePoolsTemplateSpec
    replicas: 2
    spec:
      template:
        <<: *machinePoolsTemplateSpecTemplate

  redis:
    enabled: false
    annotations: {}
    labels: {}
    managed:
      spec:
        additionalLabels: {}
        diskSizeGb: 10
        diskType: "pd-ssd"
        kubernetesLabels:
          db: redis
        kubernetesTaints:
          - effect: "NoSchedule"
            key: "key"
            value: "redis"
        machineType: "n2-standard-2"
        <<: *machinePoolsTemplateSpec
    replicas: 1
    spec:
      template:
        <<: *machinePoolsTemplateSpecTemplate

  zookeeper:
    enabled: false
    annotations: {}
    labels: {}
    managed:
      spec:
        additionalLabels: {}
        diskSizeGb: 10
        diskType: "pd-ssd"
        kubernetesLabels:
          db: zookeeper
        kubernetesTaints:
          - effect: "NoSchedule"
            key: "key"
            value: "zookeeper"
        machineType: "n2-highcpu-2"
        <<: *machinePoolsTemplateSpec
    replicas: 3
    spec:
      template:
        <<: *machinePoolsTemplateSpecTemplate
